{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Customer Churn with Explainable AI\n\nThis notebook trains a baseline model, then explains predictions with SHAP and checks fairness."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import pandas as pd, numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score, classification_report\nimport shap\n\n# === Load your data ===\n# Replace with your real paths\nX = pd.read_csv(\"../data/customers.csv\")\ny = pd.read_csv(\"../data/labels.csv\")[\"churned\"]\n\n# Basic split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Baseline model\npipe = make_pipeline(StandardScaler(with_mean=False), LogisticRegression(max_iter=200))\npipe.fit(X_train, y_train)\nproba = pipe.predict_proba(X_test)[:,1]\nprint(\"ROC AUC:\", roc_auc_score(y_test, proba).round(3))\nprint(classification_report(y_test, (proba>0.5).astype(int)))\n\n# === SHAP explanations ===\nexplainer = shap.Explainer(pipe.predict_proba, X_train, feature_names=X_train.columns.tolist())\nshap_values = explainer(X_test)\nshap.plots.beeswarm(shap_values[:,:,1], show=False)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Fairness (example placeholder)\nCompute metrics across a subgroup column, e.g., `X['segment']`."
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}